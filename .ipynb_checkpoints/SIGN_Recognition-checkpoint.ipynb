{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate additional data by transforming available data\n",
    "- Used ImageDataGenerator to create additional data by modifying available data from the train set\n",
    "- For each example in train set 5 more examples are created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 6 classes.\n",
      "Found 30 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = train_data_gen.flow_from_directory('./data/train',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=5,\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 class_mode='categorical')\n",
    "test_set = test_data_gen.flow_from_directory('./data/test',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size=5,\n",
    "                                                 color_mode='grayscale',\n",
    "                                                 class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Defination and Compilation\n",
    "- Model consists of 2 x (CONV->POOL) layers followed by 1 dense layer\n",
    "- As the train data and test data comes from the similar distribution and I am using data-generators variance is not much\n",
    "- ADAM optimizer is used to optimize the categorical_crossentropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Build the model\n",
    "model = Sequential()\n",
    "# 1st Convolution layer followed by max-pooling\n",
    "model.add(Convolution2D(32, (3, 3), input_shape=(64, 64, 1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# 2nd Convolution layer followed by max-pooling\n",
    "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Flatten the image to feed it to dese layers\n",
    "model.add(Flatten())\n",
    "\n",
    "#Fully connected layers (1-hidden layer and 1-output layer)\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=6, activation='softmax'))\n",
    "\n",
    "#Compile the model with ADAM\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "- Model is trained on the train_set generated using ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.6151 - accuracy: 0.7520\n",
      "Epoch 2/5\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.1634 - accuracy: 0.9430\n",
      "Epoch 3/5\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0716 - accuracy: 0.9800\n",
      "Epoch 4/5\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0545 - accuracy: 0.9793\n",
      "Epoch 5/5\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0297 - accuracy: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x28b95bcd860>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_set, \n",
    "                   steps_per_epoch=600,\n",
    "                   epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model and weights are saved for the future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sign_recognition_model.model')\n",
    "model.save_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "- Model is tested on the test set\n",
    "- Vary the index between 0 to 4 to test the model on different images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 5\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('sign_recognition_model.model')\n",
    "predictions = model.predict_generator(test_set)\n",
    "x,y = test_set.next()\n",
    "# choose i between 0 to 4\n",
    "i = 0\n",
    "image = x[i]\n",
    "plt.imshow(image.reshape((64, 64)), cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print('Prediction: '+str(np.argmax(predictions[i+5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Performance on the Test-set\n",
    "- Model gives 96.67% accuracy on the test set, which confirms that the model does not have bias/variance issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test-set: 0.9666666388511658\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate_generator(test_set, steps=30)\n",
    "print('Accuracy on the test-set: ' + str(test_acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
